{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "# Import some libraries\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Import some data\n",
    "digits = load_digits()\n",
    "# Show dimensionality\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  what is the type of the data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we print the data set\n",
    "# we found a ditionnary\n",
    "digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the list of keys\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many pixel has one data instance ?\n",
    "\n",
    "Attribute Information: 8x8 image of integer pixels in the range 0..16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8, 8)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A= digits.images[[41]]\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show one data\n",
    "\n",
    "plt.gray() \n",
    "plt.matshow(digits.images[41]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 100 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show several data for each label (== category) \n",
    "\n",
    "X = digits.images\n",
    "\n",
    "Y = digits.target\n",
    "\n",
    "n_digits = np.unique(Y)\n",
    "\n",
    "M = 10\n",
    "dim = int(np.sqrt(X.shape[1]))\n",
    "\n",
    "fig, axs = plt.subplots(len(n_digits), M, figsize=(12, 12))\n",
    "\n",
    "for i, d in enumerate(n_digits):\n",
    "    for j in range(M):\n",
    "        \n",
    "        axs[i,j].imshow(X[Y == d][j])\n",
    "        axs[i,j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the type of data of one pixel ? what does it represents ?\n",
    "\n",
    "The type of dada is the float and that represent the grad level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Prepare your ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "# define X : Features and Y : Target\n",
    "\n",
    "print(digits.data [0])\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print(digits.images[0])\n",
    "print(digits.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that digits.data and digits.images represent the same information. The only difference is their dimensions. The first is represented in 2 dimensions (1797, 64) and the second in 3 dimensions (1797, 8, 8). For the rest, we choose X = digits.data instead of X = digits.images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y is defined as \n",
    "Y = digits.target\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equation of the precision and recall \n",
    "\n",
    "Precision and recall are defined as : \n",
    "\n",
    "Precision = TP / TP + FP\n",
    "\n",
    "Recall = TP / TP + FN\n",
    "\n",
    "where : \n",
    "\n",
    "TP : True Positive \n",
    "FP : False Positive\n",
    "FN : False Negative\n",
    "\n",
    "La précision permet de répondre à la question suivante :\n",
    "Quelle proportion d'identifications positives était effectivement correcte ?\n",
    "Ainsi, un modèle ne produisant aucun faux positif a une précision de 1,0 et plus un modèle produit de Faux positive (FP) est plus sa précision diminue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from  sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 1)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redimensionner Y , X\n",
    "Y = digits.target\n",
    "\n",
    "Y = Y.reshape(Y.shape[0],1)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = digits.images.copy()\n",
    "Y = digits.target.copy()\n",
    "\n",
    "X= X.reshape(X.shape[0],64)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We create 2 category where the numbre 7 is replaced by 1 and all the other numbres are replaced by 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[Y != 7] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[Y == 7] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape\n",
    "X = digits.data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define  X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size =0.5, random_state=42)\n",
    "#print(\"Train set X : \", X_train)\n",
    "#print(\"Test set  X: \", X_test)\n",
    "\n",
    "#print(\"Train set y: \", Y_train)\n",
    "#print(\"Test set y: \", Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Predict Digits\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By score() :\n",
      "Accuracy train  : 1.0\n",
      "test_size =0.5\n",
      "Accuracy test : 0.9944\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0, max_iter = 200)\n",
    "\n",
    "start = time()\n",
    "model.fit(X_train,Y_train)\n",
    "T1= time()-start\n",
    "\n",
    "\n",
    "S = model.score(X_train,Y_train)\n",
    "S1 = round(model.score(X_test,Y_test),4)\n",
    "\n",
    "print ('By score() :')\n",
    "print(\"Accuracy train  :\", S )\n",
    "print (\"test_size =0.5\")\n",
    "print(\"Accuracy test :\", S1 ) \n",
    " \n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "Test_size1 = 0.5\n",
    "A1 = round(metrics.accuracy_score(Y_test, Y_pred),4)\n",
    "P1 = round(metrics.precision_score(Y_test, Y_pred),4)\n",
    "R1 = round(metrics.recall_score(Y_test, Y_pred),4)\n",
    "T1 = round(T1,4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = []\n",
    "P = []\n",
    "R = []\n",
    "T = []\n",
    "A.append(A1)\n",
    "P.append(P1)\n",
    "R.append(R1)\n",
    "T.append(T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model.predict([X[7]]))\n",
    "                     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Used as a statistical measure of how well binary claccification test correctly identifies or excludes a condition. That is, the accuracy is the proportion of correct predictions\n",
    "(both true positives and true negatives) among the total number of cases examined.\n",
    "\n",
    "\n",
    "    Accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "\n",
    "\n",
    "where: TP = True positive; FP = False positive; TN = True negative; FN = False negative \n",
    "\n",
    "It return the mean accuracy on the given test data and labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[812,   0],\n",
       "       [  0,  87]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(Y_test, model.predict(X_test))\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By score() :\n",
      "Accuracy train  : 1.0\n",
      "test_size =0.5\n",
      "Accuracy test : 0.9944\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0, max_iter = 200)\n",
    "\n",
    "start = time()\n",
    "model.fit(X_train,Y_train)\n",
    "T2= time()-start\n",
    "\n",
    "S2 = model.score(X_train,Y_train)\n",
    "S2T = round(model.score(X_test,Y_test),4)\n",
    "print ('By score() :')\n",
    "print(\"Accuracy train  :\", S2 )\n",
    "print (\"test_size =0.5\")\n",
    "print(\"Accuracy test :\", S2T ) \n",
    " \n",
    "\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "Test_size1 = 0.5\n",
    "A2 = round(metrics.accuracy_score(Y_test, Y_pred),4)\n",
    "P2 = round(metrics.precision_score(Y_test, Y_pred),4)\n",
    "R2 = round(metrics.recall_score(Y_test, Y_pred),4)\n",
    "T2 = round(T2,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.append(A2)\n",
    "P.append(P2)\n",
    "R.append(R2)\n",
    "T.append(T2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors Classification\n",
    "\n",
    "Classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point.\n",
    "We try to implement KNeighborsClassifier based on the nearest neighbors of each query point, where is an integer value specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By score() :\n",
      "Accuracy train  : 1.0\n",
      "test_size =0.5\n",
      "Accuracy test : 0.9967\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model.fit(X_train,Y_train)\n",
    "T3= time()-start\n",
    "\n",
    "S3 = model.score(X_train,Y_train)\n",
    "S3T = round(model.score(X_test,Y_test),4)\n",
    "\n",
    "print ('By score() :')\n",
    "print(\"Accuracy train  :\", S3 )\n",
    "print (\"test_size =0.5\")\n",
    "print(\"Accuracy test :\", S3T ) \n",
    " \n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "Test_size1 = 0.5\n",
    "A3 = round(metrics.accuracy_score(Y_test, Y_pred),4)\n",
    "P3 = round(metrics.precision_score(Y_test, Y_pred),4)\n",
    "R3 = round(metrics.recall_score(Y_test, Y_pred),4)\n",
    "T3 = round(T3,4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.append(A3)\n",
    "P.append(P3)\n",
    "R.append(R3)\n",
    "T.append(T3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By score() :\n",
      "Accuracy train  : 1.0\n",
      "test_size =0.5\n",
      "Accuracy test : 0.9815\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "start = time()\n",
    "model.fit(X_train,Y_train)\n",
    "T4= time()-start\n",
    "\n",
    "S = model.score(X_train,Y_train)\n",
    "S1 = round(model.score(X_test,Y_test),4)\n",
    "print ('By score() :')\n",
    "print(\"Accuracy train  :\", S )\n",
    "print (\"test_size =0.5\")\n",
    "print(\"Accuracy test :\", S1 ) \n",
    " \n",
    "\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "A4 = round(metrics.accuracy_score(Y_test, Y_pred),4)\n",
    "P4 = round(metrics.precision_score(Y_test, Y_pred),4)\n",
    "R4 = round(metrics.recall_score(Y_test, Y_pred),4)\n",
    "T4 = round(T4,4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.append(A4)\n",
    "P.append(P4)\n",
    "R.append(R4)\n",
    "T.append(T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters       RegLoc         Redlin             KNeighbors         DecisionTree\n",
      "Accuracy:        0.9944         0.9944             0.9967             0.9655\n",
      "Precision:       0.9556         0.9556             0.9667             0.7745\n",
      "Recall:          0.9885         0.9885             1.0             0.908\n",
      "Time:            0.311         0.1103             0.0092             0.0113\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameters       %s         %s             %s         %s\" %(\"RegLoc\",\"Redlin\",\"KNeighbors\",\"DecisionTree\"))\n",
    "print(\"Accuracy:        %s         %s             %s             %s\" %(A1, A2, A3, A4)) \n",
    "print(\"Precision:       %s         %s             %s             %s\" %(P1, P2, P3, P4))\n",
    "print(\"Recall:          %s         %s             %s             %s\" %(R1, R2, R3, R4))\n",
    "print(\"Time:            %s         %s             %s             %s\" %(T1, T2, T3, T4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we notice that the fastest model is the Decision Tree but it is not the most precise for test_size = 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By score() :\n",
      "Accuracy train  : 1.0\n",
      "test_size =0.3\n",
      "Accuracy test : 0.9815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sacia/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#Model = Logistic Regression with differents test_size\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size =0.30, random_state=42)\n",
    "model = LogisticRegression(random_state=0)\n",
    "\n",
    "start = time()\n",
    "model.fit(X_train,Y_train)\n",
    "T2= time()-start\n",
    "\n",
    "\n",
    "S = model.score(X_train,Y_train)\n",
    "S2 = model.score(X_test,Y_test)\n",
    "\n",
    "Test_size1 = 0.3\n",
    "\n",
    "print ('By score() :')\n",
    "print(\"Accuracy train  :\", S )\n",
    "print (\"test_size :\", Test_size1)\n",
    "print(\"Accuracy test :\", S1 ) \n",
    " \n",
    "\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "A2 = round(metrics.accuracy_score(Y_test, Y_pred),4)\n",
    "P2 = round(metrics.precision_score(Y_test, Y_pred),4)\n",
    "R2 = round(metrics.recall_score(Y_test, Y_pred),4)\n",
    "T2 = round(T2,4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many input data the algorithms needs the be efficient (and why) ?\n",
    "To answer this question we will use differents test_size (0.3 , 0.5 , 0.9). We observe that the model remains efficient with 10 % of data and with the fastest time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By score() :\n",
      "Accuracy train  : 1.0\n",
      "test_size = 0.9\n",
      "Accuracy test : 0.9858\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size =0.90, random_state=42)\n",
    "model = LogisticRegression(random_state=0, max_iter = 200)\n",
    "\n",
    "start = time()\n",
    "model.fit(X_train,Y_train)\n",
    "T3= time()-start\n",
    "\n",
    "\n",
    "S = model.score(X_train,Y_train)\n",
    "S3 = model.score(X_test,Y_test)\n",
    "\n",
    "Test_size1 = 0.9\n",
    "\n",
    "print ('By score() :')\n",
    "print(\"Accuracy train  :\", S )\n",
    "print (\"test_size =\", Test_size1)\n",
    "print(\"Accuracy test :\", round(S3,4) ) \n",
    " \n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "A3 = round(metrics.accuracy_score(Y_test, Y_pred),4)\n",
    "P3 = round(metrics.precision_score(Y_test, Y_pred),4)\n",
    "R3 = round(metrics.recall_score(Y_test, Y_pred),4)\n",
    "T3 = round(T3,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = Logistic Regression with differents test_size\n",
      "Test_size        0.3           0.5           0.9\n",
      "Accuracy:        0.9926        0.9944        0.9858\n",
      "Precision:       0.9474        0.9556        0.9337\n",
      "Recall:          0.9818        0.9885        0.9281\n",
      "Time:            0.051        0.311        0.0438\n"
     ]
    }
   ],
   "source": [
    "print(\"Model = Logistic Regression with differents test_size\")\n",
    "print(\"Test_size        %s           %s           %s\" %(\"0.3\",\"0.5\",\"0.9\"))\n",
    "print(\"Accuracy:        %s        %s        %s\" %(A2, A1, A3)) \n",
    "print(\"Precision:       %s        %s        %s\" %(P2, P1, P3))\n",
    "print(\"Recall:          %s        %s        %s\" %(R2, R1, R3))\n",
    "print(\"Time:            %s        %s        %s\" %(T2, T1, T3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['RegLoc', 'Reglin', 'KNeighbors', 'DecisionTree'],\n",
       "       ['0.9944', '0.9944', '0.9967', '0.9655'],\n",
       "       ['0.9556', '0.9643', '0.9667', '0.7745'],\n",
       "       ['0.9885', '0.9818', '1.0', '0.908'],\n",
       "       ['0.311', '0.1308', '0.0092', '0.0113']], dtype='<U12')"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =['RegLoc','Reglin','KNeighbors','DecisionTree']\n",
    "result = np.array([model,A,P,R,T])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['RegLoc' '0.9944' '0.9556' '0.9885' '0.311']\n",
      " ['Reglin' '0.9944' '0.9643' '0.9818' '0.1308']\n",
      " ['KNeighbors' '0.9967' '0.9667' '1.0' '0.0092']\n",
      " ['DecisionTree' '0.9655' '0.7745' '0.908' '0.0113']]\n"
     ]
    }
   ],
   "source": [
    "resultT = result.T\n",
    "print(resultT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RegLoc', 'Reglin', 'KNeighbors', 'DecisionTree'], dtype='<U12')"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultT[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1: RegLoc  2: Reglin  v3: KNeighbors 4:DecisionTree\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter (axis, resultT[:,1], c= 'r', label='Accuracy')\n",
    "#plt.scatter (axis, resultT[:,2], c= 'b', label='Precision')\n",
    "#plt.scatter (axis, resultT[:,3], c= 'black', label='Recall')\n",
    "#plt.scatter (axis, resultT[:,4], c= 'green', label='Time')\n",
    "plt.legend()\n",
    "print(' 1: RegLoc  2: Reglin  v3: KNeighbors 4:DecisionTree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Multi-class classification\n",
    "We will try to use binary case predict to do the multi-class classification. We choose the model with test_size = 0.9 beacause it is the fastest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.images.copy()\n",
    "Y = digits.target.copy()\n",
    "\n",
    "X= X.reshape(X.shape[0],64)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = int(input(\"Please introduce a number between 0 and 9 : \"))\n",
    "\n",
    "\n",
    "\n",
    "Y[Y != N] = 0\n",
    "Y[Y == N] = 1\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size =0.90, random_state=42)\n",
    "model = LogisticRegr0ession(random_state=0, max_iter = 200)\n",
    "\n",
    "#S = model.score(X_train,Y_train)\n",
    "#S5 = model.score(X_test,Y_test)\n",
    "\n",
    "#Test_size1 = 0.9\n",
    "\n",
    "#print ('By score() :')\n",
    "#print(\"Accuracy train  :\", S )\n",
    "#print (\"test_size =\", Test_size1)\n",
    "#print(\"Accuracy test :\", round(S3,4) ) \n",
    " \n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "print(model.predict([X[N]]))\n",
    "\n",
    "\n",
    "A5 = round(metrics.accuracy_score(Y_test, Y_pred),4)\n",
    "P5 = round(metrics.precision_score(Y_test, Y_pred),4)\n",
    "R5 = round(metrics.recall_score(Y_test, Y_pred),4)\n",
    "T5 = round(T3,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I will finish it later !!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
